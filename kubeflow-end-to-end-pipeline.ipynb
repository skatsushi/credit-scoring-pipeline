{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208dbc67-8b93-4fb4-aa88-eaa34d7b738b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_10135/3312377993.py:1: DeprecationWarning: The module `kfp.v2` is deprecated and will be removed in a futureversion. Please import directly from the `kfp` namespace, instead of `kfp.v2`.\n",
      "  from kfp.v2 import dsl\n"
     ]
    }
   ],
   "source": [
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Input,Output,Metrics,component,Model,ClassificationMetrics)\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "from typing import NamedTuple\n",
    "from kfp.v2 import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c5f263-bbbe-401b-8ffd-bec962374f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/kfp/dsl/component_decorator.py:119: FutureWarning: Python 3.7 has reached end-of-life. The default base_image used by the @dsl.component decorator will switch from 'python:3.7' to 'python:3.8' on April 23, 2024. To ensure your existing components work with versions of the KFP SDK released after that date, you should provide an explicit base_image argument and ensure your component works as intended on Python 3.8.\n",
      "  return component_factory.create_component_from_func(\n"
     ]
    }
   ],
   "source": [
    "@component(\n",
    "packages_to_install=[\"gcsfs\",\"pandas\",\"google-cloud-storage\"]\n",
    ")\n",
    "def validate_input_ds(filename:str)-> NamedTuple(\"output\", [(\"input_validation\", str)]):\n",
    "\n",
    "    import logging\n",
    "    from google.cloud import storage\n",
    "    import pandas as pd\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    logging.info(f\"Reading file: {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "    expected_num_cols = 21\n",
    "    num_cols = len(df.columns)\n",
    "\n",
    "    logging.info(f\"Number of columns: {num_cols}\")\n",
    "    \n",
    "    input_validation=\"true\"\n",
    "    \n",
    "    if num_cols != expected_num_cols:\n",
    "        input_validation=\"false\"\n",
    "        \n",
    "    expected_col_names = ['CREDIT_REQUEST_ID', 'CREDIT_AMOUNT', 'CREDIT_DURATION', 'PURPOSE',\n",
    "       'INSTALLMENT_COMMITMENT', 'OTHER_PARTIES', 'CREDIT_STANDING',\n",
    "       'CREDIT_SCORE', 'CHECKING_BALANCE', 'SAVINGS_BALANCE',\n",
    "       'EXISTING_CREDITS', 'ASSETS', 'HOUSING', 'QUALIFICATION', 'JOB_HISTORY',\n",
    "       'AGE', 'SEX', 'MARITAL_STATUS', 'NUM_DEPENDENTS', 'RESIDENCE_SINCE',\n",
    "       'OTHER_PAYMENT_PLANS']\n",
    "\n",
    "    if set(df.columns) != set(expected_col_names):\n",
    "        input_validation=\"false\"\n",
    "\n",
    "    return (input_validation,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "906916e5-f715-4790-bfef-5143bff89cef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "packages_to_install=[\"google-cloud-aiplatform\",\"gcsfs\",\"xgboost\",\"scikit-learn\",\"pandas\",\"google-cloud-storage\"]\n",
    ")\n",
    "def custom_training_job_component(\n",
    "    max_depth:int,\n",
    "    learning_rate:float,\n",
    "    n_estimators:int,\n",
    "    metrics: Output[Metrics],\n",
    "    performance_metrics: Output[ClassificationMetrics]\n",
    ")->NamedTuple(\"output\", [(\"model_validation\", str)]):\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    from xgboost import XGBClassifier\n",
    "    from google.cloud import storage\n",
    "    from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(\"skatsushi-kubeflow\")\n",
    "\n",
    "    def purpose_encode(x):\n",
    "        if x == \"Consumer Goods\":\n",
    "            return 1\n",
    "        elif x == \"Vehicle\":\n",
    "            return 2\n",
    "        elif x == \"Tuition\":\n",
    "            return 3\n",
    "        elif x == \"Business\":\n",
    "            return 4\n",
    "        elif x == \"Repairs\":\n",
    "            return 5\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def other_parties_encode(x):\n",
    "        if x == \"Guarantor\":\n",
    "            return 1\n",
    "        elif x == \"Co-Applicant\":\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def qualification_encode(x):\n",
    "        if x == \"unskilled\":\n",
    "            return 1\n",
    "        elif x == \"skilled\":\n",
    "            return 2\n",
    "        elif x == \"highly skilled\":\n",
    "            return 3\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def credit_standing_encode(x):\n",
    "        if x == \"good\":\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def assets_encode(x):\n",
    "        if x == \"Vehicle\":\n",
    "            return 1\n",
    "        elif x == \"Investments\":\n",
    "            return 2\n",
    "        elif x == \"Home\":\n",
    "            return 3\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def housing_encode(x):\n",
    "        if x == \"rent\":\n",
    "            return 1\n",
    "        elif x == \"own\":\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def marital_status_encode(x):\n",
    "        if x == \"Married\":\n",
    "            return 1\n",
    "        elif x == \"Single\":\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def other_payment_plans_encode(x):\n",
    "        if x == \"bank\":\n",
    "            return 1\n",
    "        elif x == \"stores\":\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def sex_encode(x):\n",
    "        if x == \"M\":\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def credit_score_decode(x):\n",
    "        return \"Approved\" if x == 1 else \"Denied\"\n",
    "\n",
    "    def preprocess_data(df):\n",
    "        df[\"PURPOSE_CODE\"] = df[\"PURPOSE\"].apply(purpose_encode)\n",
    "        df[\"OTHER_PARTIES_CODE\"] = df[\"OTHER_PARTIES\"].apply(other_parties_encode)\n",
    "        df[\"QUALIFICATION_CODE\"] = df[\"QUALIFICATION\"].apply(qualification_encode)\n",
    "        df[\"CREDIT_STANDING_CODE\"] = df[\"CREDIT_STANDING\"].apply(credit_standing_encode)\n",
    "        df[\"ASSETS_CODE\"] = df[\"ASSETS\"].apply(assets_encode)\n",
    "        df[\"HOUSING_CODE\"] = df[\"HOUSING\"].apply(housing_encode)\n",
    "        df[\"MARITAL_STATUS_CODE\"] = df[\"MARITAL_STATUS\"].apply(marital_status_encode)\n",
    "        df[\"OTHER_PAYMENT_PLANS_CODE\"] = df[\"OTHER_PAYMENT_PLANS\"].apply(other_payment_plans_encode)\n",
    "        df[\"SEX_CODE\"] = df[\"SEX\"].apply(sex_encode)\n",
    "\n",
    "        columns_to_drop = [\"PURPOSE\", \"OTHER_PARTIES\", \"QUALIFICATION\", \"CREDIT_STANDING\",\n",
    "                        \"ASSETS\", \"HOUSING\", \"MARITAL_STATUS\", \"OTHER_PAYMENT_PLANS\", \"SEX\"]\n",
    "        df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def split_data(df):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df.drop('CREDIT_STANDING_CODE', axis=1), \n",
    "                                                            df['CREDIT_STANDING_CODE'], test_size=0.30)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "    def train_model(X_train, y_train,max_depth,learning_rate,n_estimators):    \n",
    "        model = XGBClassifier(\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=n_estimators,\n",
    "            random_state=42,\n",
    "            use_label_encoder=False\n",
    "        )    \n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "\n",
    "    def save_model_artifact(pipeline):\n",
    "        artifact_name = 'model.bst'\n",
    "        pipeline.save_model(artifact_name)\n",
    "        model_artifact = bucket.blob('credit-scoring/artifacts/'+artifact_name)\n",
    "        model_artifact.upload_from_filename(artifact_name)\n",
    "\n",
    "    def evaluate_model(model, X_test, y_test):\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        \n",
    "        metrics.log_metric(\"accurancy\", accuracy)\n",
    "        metrics.log_metric(\"precision\", precision)\n",
    "        metrics.log_metric(\"recall\", recall)\n",
    "\n",
    "        performance_metrics.log_confusion_matrix(\n",
    "           [\"False\", \"True\"],\n",
    "           confusion_matrix(y_test, y_pred).tolist(), \n",
    "        )\n",
    "        return accuracy,precision,recall\n",
    "        # print(\"Classification Report:\")\n",
    "        # print(classification_report(y_test, y_pred))\n",
    "        # print(\"Confusion Matrix:\")\n",
    "        # print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "    input_file = \"gs://skatsushi-kubeflow/credit-scoring/credit_files.csv\"\n",
    "    credit_df = pd.read_csv(input_file)\n",
    "    credit_df = preprocess_data(credit_df)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(credit_df)\n",
    "\n",
    "    pipeline = train_model(X_train, y_train,max_depth,learning_rate,n_estimators)\n",
    "\n",
    "    accuracy,precision,recall = evaluate_model(pipeline, X_test, y_test)\n",
    "    \n",
    "    if accuracy>0.5 and precision>0.5 :\n",
    "        save_model_artifact(pipeline)\n",
    "        model_validation=\"true\"\n",
    "    else :\n",
    "        model_validation=\"false\"\n",
    "    \n",
    "    return (model_validation,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4d42245-5d6b-4493-9196-f80a4c0200ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"]\n",
    ")\n",
    "def model_deployment()-> NamedTuple(\"endpoint_details\", [(\"endpoint\", str)]):\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    \n",
    "    aiplatform.init(project=\"skatsushi\", location=\"us-central1\", staging_bucket=\"gs://skatsushi-kubeflow\")\n",
    "    \n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=\"credit-scoring-model\",\n",
    "        artifact_uri=\"gs://skatsushi-kubeflow/credit-scoring/artifacts/\",\n",
    "        serving_container_image_uri = \"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-6:latest\",\n",
    "        sync=False\n",
    "    )\n",
    "    \n",
    "    DEPLOYED_NAME = \"creditscoring-model-endpoint\"\n",
    "    TRAFFIC_SPLIT = {\"0\": 100}\n",
    "    MIN_NODES = 1\n",
    "    MAX_NODES = 1\n",
    "\n",
    "    endpoint = model.deploy(\n",
    "        deployed_model_display_name=DEPLOYED_NAME,\n",
    "        traffic_split=TRAFFIC_SPLIT,\n",
    "        machine_type=\"n1-standard-4\",\n",
    "        min_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9e43890-e703-4435-88a1-49a670209e97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_10135/186959984.py:18: DeprecationWarning: dsl.Condition is deprecated. Please use dsl.If instead.\n",
      "  with dsl.Condition(input_validation_task.outputs[\"input_validation\"] == \"true\"):\n",
      "/var/tmp/ipykernel_10135/186959984.py:25: DeprecationWarning: dsl.Condition is deprecated. Please use dsl.If instead.\n",
      "  with dsl.Condition(model_training.outputs[\"model_validation\"] == \"true\"):\n"
     ]
    }
   ],
   "source": [
    "@dsl.pipeline(\n",
    "    pipeline_root=\"gs://skatsushi-kubeflow/credit-scoring-pipeline\",\n",
    "    name=\"credit-scoring-pipeline\",\n",
    ")\n",
    "def pipeline(\n",
    "    project: str = \"skatsushi\",\n",
    "    region: str = \"us-central1\"\n",
    "    ):\n",
    "    \n",
    "    max_depth=5\n",
    "    learning_rate=0.2\n",
    "    n_estimators=40\n",
    "    \n",
    "    file_name = \"gs://skatsushi-kubeflow/credit-scoring/credit_files.csv\"\n",
    "    \n",
    "    input_validation_task = validate_input_ds(filename=file_name)\n",
    "    \n",
    "    with dsl.Condition(input_validation_task.outputs[\"input_validation\"] == \"true\"):\n",
    "        model_training = custom_training_job_component(\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=n_estimators,\n",
    "        ).after(input_validation_task)\n",
    "        \n",
    "        with dsl.Condition(model_training.outputs[\"model_validation\"] == \"true\"):\n",
    "            task_deploy_model = model_deployment().after(model_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff60e02-663f-4d11-8033-f158cd0f5e72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/993417506239/locations/us-central1/pipelineJobs/credit-scoring-pipeline-20240810140003\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/993417506239/locations/us-central1/pipelineJobs/credit-scoring-pipeline-20240810140003')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/credit-scoring-pipeline-20240810140003?project=993417506239\n",
      "PipelineJob projects/993417506239/locations/us-central1/pipelineJobs/credit-scoring-pipeline-20240810140003 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/993417506239/locations/us-central1/pipelineJobs/credit-scoring-pipeline-20240810140003 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/993417506239/locations/us-central1/pipelineJobs/credit-scoring-pipeline-20240810140003 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/993417506239/locations/us-central1/pipelineJobs/credit-scoring-pipeline-20240810140003 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/993417506239/locations/us-central1/pipelineJobs/credit-scoring-pipeline-20240810140003 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/993417506239/locations/us-central1/pipelineJobs/credit-scoring-pipeline-20240810140003 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/993417506239/locations/us-central1/pipelineJobs/credit-scoring-pipeline-20240810140003 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/993417506239/locations/us-central1/pipelineJobs/credit-scoring-pipeline-20240810140003 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/993417506239/locations/us-central1/pipelineJobs/credit-scoring-pipeline-20240810140003 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/993417506239/locations/us-central1/pipelineJobs/credit-scoring-pipeline-20240810140003 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline,package_path='credit-scoring-deployment.json')\n",
    "\n",
    "start_pipeline = pipeline_jobs.PipelineJob(\n",
    "    display_name=\"credit-scoring-deployment-pipeline\",\n",
    "    template_path=\"credit-scoring-deployment.json\",\n",
    "    enable_caching=False,\n",
    "    location=\"us-central1\",\n",
    ")\n",
    "\n",
    "start_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106c27b-d986-4871-b8b2-a094ea1e6e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
